{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "laden-consequence",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-fight",
   "metadata": {},
   "source": [
    "####  The purpose of this program is to clear the csv files containing CICIDS2017 data from errors.\n",
    "####  the faults observed are:\n",
    "####      1-   288602 of the entries in the file \"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\" are empty / meaningless.\n",
    "####                   (e.g. \",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\")\n",
    "####\n",
    "####      2-  In the original csv files, while describing the Web Attack types such as Brute Force, XSS, Sql Injection, the character used is not recognized\n",
    "####                    by the Python-Pandas library and leads to the error.\n",
    "####                   this character (\"–\", Unicode code:8211) has been changed with another character (\"-\", Unicode code:45) to correct the error.\n",
    "####\n",
    "####   After the error correction, all the csv files were made into a single file (all_date.csv) to make it easier to process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distributed-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS OF MODULES\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "seconds = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rental-breeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This process may take 5 to 10 minutes, depending on the performance of your computer.\n",
      "\n",
      "\n",
      "\n",
      "FILENAME : Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Monday-WorkingHours.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Monday-WorkingHours.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Wednesday-workingHours.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Wednesday-workingHours.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Friday-WorkingHours-Morning.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Tuesday-WorkingHours.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "mission accomplished!\n",
      "Total operation time: =  228.5559377670288 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"This process may take 5 to 10 minutes, depending on the performance of your computer.\\n\\n\\n\")\n",
    "number=\"0123456789\"\n",
    "# CSV files names:\n",
    "csv_files=os.listdir('./DATA/') ## ALL DATA SHOULD BE UNDER THE FOLDER IN SAME DIRECTORY NAMED \"DATA\"\n",
    "\n",
    "# HEADERS OF LABELS OF DATAFRAME\n",
    "df = pd.read_csv('./DATA/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
    "main_labels = [x.strip() for x in df.columns.to_list()]\n",
    "\n",
    "main_labels2=main_labels\n",
    "main_labels=( \",\".join( i for i in main_labels ) )\n",
    "main_labels=main_labels+\"\\n\"\n",
    "main_labels\n",
    "flag=True\n",
    "\n",
    "for i in range(len(csv_files)):\n",
    "    print('FILENAME :',str(csv_files[i]))\n",
    "    ths = open(str(csv_files[i]), \"w\")\n",
    "    ths.write(main_labels)\n",
    "    with open(\"./DATA/\"+csv_files[i], \"r\") as file:\n",
    "        print('REMOVING THE inf,NaN and other errors')\n",
    "        while True:\n",
    "            try:\n",
    "                line=file.readline()\n",
    "                if  line[0] in number:# this line eliminates the headers of CSV files and incomplete streams .\n",
    "                    if \" – \" in str(line): ##  if there is \"–\" character (\"–\", Unicode code:8211) in the flow ,  it will be chanced with \"-\" character ( Unicode code:45).\n",
    "                        line=(str(line).replace(\" – \",\" - \"))\n",
    "                    line=(str(line).replace(\"inf\",\"0\"))\n",
    "                    line=(str(line).replace(\"Infinity\",\"0\"))\n",
    "                    line=(str(line).replace(\"NaN\",\"0\"))\n",
    "                    ths.write(str(line))\n",
    "                else:\n",
    "                    continue                       \n",
    "            except:\n",
    "                break\n",
    "    ths.close()\n",
    " \n",
    "    df=pd.read_csv(str(csv_files[i]),low_memory=False)\n",
    "    df=df.fillna(0)\n",
    "    \n",
    "    string_features=[\"Flow Bytes/s\",\"Flow Packets/s\"]\n",
    "    for ii in string_features: #Some data in the \"Flow Bytes / s\" and \"Flow Packets / s\" columns are not numeric. Fixing this bug in this loop\n",
    "        df[ii]=df[ii].replace('Infinity', -1)\n",
    "        df[ii]=df[ii].replace('NaN', 0)\n",
    "        number_or_not=[]\n",
    "        for iii in df[ii]:\n",
    "            try:\n",
    "                k=int(float(iii))\n",
    "                number_or_not.append(int(k))\n",
    "            except:\n",
    "                number_or_not.append(iii)\n",
    "        df[ii]=number_or_not\n",
    "\n",
    "\n",
    "\n",
    "    string_features=[]\n",
    "    for j in main_labels2: # In this section, non-numeric (string and / or categorical) properties (columns) are detected.\n",
    "        if df[j].dtype==\"object\":\n",
    "            string_features.append(j)\n",
    "    try:\n",
    "        string_features.remove('Label')#The \"Label\" property was removed from the list. Because it has to remain \"categorical\" for using with different machine learning approach.\n",
    "    except:\n",
    "        print(\"error!\")\n",
    "    labelencoder_X = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "    print('LABEL ENCODING')\n",
    "    for ii in string_features: ## In this loop, non-numeric (string and/or categorical) properties converted to numeric features.\n",
    "        try:\n",
    "            df[ii]=labelencoder_X.fit_transform(df[ii])\n",
    "        except:\n",
    "            df[ii]=df[ii].replace('Infinity', -1)\n",
    "    df=df.drop(main_labels2[61], axis=1) ## Column 61 is deleted because it is unnecessary, column 41 (\"Fwd Header Length\" feature) had be mistakenly rewritten.\n",
    "\n",
    "\n",
    "    print('MERGING INTO ONE FILE')\n",
    "    ##All CSV files are merged into a single file.\n",
    "    if flag:\n",
    "        df.to_csv('all_data.csv' ,index = False)\n",
    "        flag=False\n",
    "    else:\n",
    "        df.to_csv('all_data.csv' ,index = False,header=False,mode=\"a\")\n",
    "    #os.remove(str(csv_files[i]))\n",
    "    print(\"The pre-processing phase of the \",csv_files[i],\" file is completed.\\n\")\n",
    "    \n",
    "\n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-september",
   "metadata": {},
   "source": [
    "## STATISTICS OF THE DATA\n",
    "\n",
    "###### The data will not be equally divided into labels which can make the model learn wrong as it always give more weight to BENIGN. To avoid that we will reduce the data\n",
    "\n",
    "##### Also the data is too big to be used in this processor. So we will go for reduction of data option .  :-)\n",
    "### Lets see the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "detected-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  all_data.csv files is required for the operation of the program.\n",
    "  all_data.csv file must be located in the same directory as the program.\n",
    "\n",
    "  The purpose of this program is to provide statistics about the data contained in the dataset.\n",
    "  Considering that some of the data are very large and some of them are very small, \n",
    "  the graphics are created in three separate groups, so that all data can be seen:\n",
    "        big: labels with more than 11000 numbers\n",
    "        medium: labels with numbers between 600 and 11000\n",
    "        small: labels with fewer than 600 numbers\n",
    "'''\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import time\n",
    "seconds = time.time()\n",
    "\n",
    "#  graph creation function\n",
    "def graph(objects,performance,x_label,y_label):\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "    plt.yticks(y_pos, objects)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.title(y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "equivalent-casino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENIGN              2117531\n",
      "DoS Hulk             231073\n",
      "PortScan             158930\n",
      "DDoS                 128027\n",
      "DoS GoldenEye         10293\n",
      "FTP-Patator            7938\n",
      "SSH-Patator            5897\n",
      "DoS slowloris          5796\n",
      "DoS Slowhttptest       5499\n",
      "Bot                    1966\n",
      "Infiltration             36\n",
      "Heartbleed               11\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## TIME TAKING CELL :(\n",
    "df=pd.read_csv('all_data.csv', usecols=[\"Label\"])\n",
    "print(df.iloc[:,0].value_counts())\n",
    "a=(df.iloc[:,0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WHOLE DATA IS FAVOURING THE BENIGN label... \n",
    "key=a.keys()\n",
    "values=a.values\n",
    "small_labels=[]\n",
    "small_values=[]\n",
    "big_labels=[]\n",
    "big_values=[]\n",
    "medium_labels=[]\n",
    "medium_values=[]\n",
    "attack=0\n",
    "benign=0\n",
    "\n",
    "## the attacks are grouped under 3 groups,\n",
    "## so that all values can be seen on the graph.\n",
    "for i in range(0,len(values)):\n",
    "    if values[i]>11000:\n",
    "        big_labels.append(str(key[i]))\n",
    "        big_values.append(values[i])\n",
    "    elif values[i]<600:\n",
    "        small_labels.append(str(key[i]))\n",
    "        small_values.append(values[i]) \n",
    "    else:\n",
    "        medium_labels.append(str(key[i]))\n",
    "        medium_values.append(values[i])\n",
    "\n",
    "    if str(key[i])==\"BENIGN\":\n",
    "        benign+=values[i]\n",
    "    else:\n",
    "        attack+=values[i]\n",
    "        \n",
    "key =[benign,attack]\n",
    "\n",
    "print('There are total attacks :',attack,'out of total data of',attack+benign)\n",
    "\n",
    "#functions are called to create a chartes\n",
    "labels=[\"BENIGN %\"+str(round(benign/(benign+attack),2)*100),\n",
    "        \"ATTACK %\"+str(round(attack/(benign+attack),2)*100)]\n",
    "print\n",
    "graph(big_labels,big_values,\"Numbers\",\"Attacks Labels - High-number group\")\n",
    "graph(medium_labels,medium_values,\"Numbers\",\"Attacks Labels - Medium-number group\")\n",
    "graph(small_labels,small_values,\"Numbers\",\"Attacks Labels - Small -number group\")\n",
    "graph(labels,key,\"Numbers\",\"Attack and Benign Percentage\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-pointer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-meditation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
