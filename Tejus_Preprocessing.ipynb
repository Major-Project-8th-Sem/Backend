{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "laden-consequence",
   "metadata": {},
   "source": [
    "## Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-fight",
   "metadata": {},
   "source": [
    "####  The purpose of this program is to clear the csv files containing CICIDS2017 data from errors.\n",
    "####  the faults observed are:\n",
    "####      1-   288602 of the entries in the file \"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\" are empty / meaningless.\n",
    "####                   (e.g. \",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\")\n",
    "####\n",
    "####      2-  In the original csv files, while describing the Web Attack types such as Brute Force, XSS, Sql Injection, the character used is not recognized\n",
    "####                    by the Python-Pandas library and leads to the error.\n",
    "####                   this character (\"–\", Unicode code:8211) has been changed with another character (\"-\", Unicode code:45) to correct the error.\n",
    "####\n",
    "####   After the error correction, all the csv files were made into a single file (all_date.csv) to make it easier to process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distributed-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS OF MODULES\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "seconds = time.time()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rental-breeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This process may take 5 to 10 minutes, depending on the performance of your computer.\n",
      "\n",
      "\n",
      "\n",
      "FILENAME : Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Monday-WorkingHours.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Monday-WorkingHours.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Wednesday-workingHours.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Wednesday-workingHours.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Friday-WorkingHours-Morning.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "FILENAME : Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "REMOVING THE inf,NaN and other errors\n",
      "LABEL ENCODING\n",
      "MERGING INTO ONE FILE\n",
      "The pre-processing phase of the  Tuesday-WorkingHours.pcap_ISCX.csv  file is completed.\n",
      "\n",
      "mission accomplished!\n",
      "Total operation time: =  228.5559377670288 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"This process may take 5 to 10 minutes, depending on the performance of your computer.\\n\\n\\n\")\n",
    "number=\"0123456789\"\n",
    "# CSV files names:\n",
    "csv_files=os.listdir('./DATA/') ## ALL DATA SHOULD BE UNDER THE FOLDER IN SAME DIRECTORY NAMED \"DATA\"\n",
    "\n",
    "# HEADERS OF LABELS OF DATAFRAME\n",
    "df = pd.read_csv('./DATA/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
    "main_labels = [x.strip() for x in df.columns.to_list()]\n",
    "\n",
    "main_labels2=main_labels\n",
    "main_labels=( \",\".join( i for i in main_labels ) )\n",
    "main_labels=main_labels+\"\\n\"\n",
    "main_labels\n",
    "flag=True\n",
    "\n",
    "for i in range(len(csv_files)):\n",
    "    print('FILENAME :',str(csv_files[i]))\n",
    "    ths = open(str(csv_files[i]), \"w\")\n",
    "    ths.write(main_labels)\n",
    "    with open(\"./DATA/\"+csv_files[i], \"r\") as file:\n",
    "        print('REMOVING THE inf,NaN and other errors')\n",
    "        while True:\n",
    "            try:\n",
    "                line=file.readline()\n",
    "                if  line[0] in number:# this line eliminates the headers of CSV files and incomplete streams .\n",
    "                    if \" – \" in str(line): ##  if there is \"–\" character (\"–\", Unicode code:8211) in the flow ,  it will be chanced with \"-\" character ( Unicode code:45).\n",
    "                        line=(str(line).replace(\" – \",\" - \"))\n",
    "                    line=(str(line).replace(\"inf\",\"0\"))\n",
    "                    line=(str(line).replace(\"Infinity\",\"0\"))\n",
    "                    line=(str(line).replace(\"NaN\",\"0\"))\n",
    "                    ths.write(str(line))\n",
    "                else:\n",
    "                    continue                       \n",
    "            except:\n",
    "                break\n",
    "    ths.close()\n",
    " \n",
    "    df=pd.read_csv(str(csv_files[i]),low_memory=False)\n",
    "    df=df.fillna(0)\n",
    "    \n",
    "    string_features=[\"Flow Bytes/s\",\"Flow Packets/s\"]\n",
    "    for ii in string_features: #Some data in the \"Flow Bytes / s\" and \"Flow Packets / s\" columns are not numeric. Fixing this bug in this loop\n",
    "        df[ii]=df[ii].replace('Infinity', -1)\n",
    "        df[ii]=df[ii].replace('NaN', 0)\n",
    "        number_or_not=[]\n",
    "        for iii in df[ii]:\n",
    "            try:\n",
    "                k=int(float(iii))\n",
    "                number_or_not.append(int(k))\n",
    "            except:\n",
    "                number_or_not.append(iii)\n",
    "        df[ii]=number_or_not\n",
    "\n",
    "\n",
    "\n",
    "    string_features=[]\n",
    "    for j in main_labels2: # In this section, non-numeric (string and / or categorical) properties (columns) are detected.\n",
    "        if df[j].dtype==\"object\":\n",
    "            string_features.append(j)\n",
    "    try:\n",
    "        string_features.remove('Label')#The \"Label\" property was removed from the list. Because it has to remain \"categorical\" for using with different machine learning approach.\n",
    "    except:\n",
    "        print(\"error!\")\n",
    "    labelencoder_X = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "    print('LABEL ENCODING')\n",
    "    for ii in string_features: ## In this loop, non-numeric (string and/or categorical) properties converted to numeric features.\n",
    "        try:\n",
    "            df[ii]=labelencoder_X.fit_transform(df[ii])\n",
    "        except:\n",
    "            df[ii]=df[ii].replace('Infinity', -1)\n",
    "    df=df.drop(main_labels2[61], axis=1) ## Column 61 is deleted because it is unnecessary, column 41 (\"Fwd Header Length\" feature) had be mistakenly rewritten.\n",
    "\n",
    "\n",
    "    print('MERGING INTO ONE FILE')\n",
    "    ##All CSV files are merged into a single file.\n",
    "    if flag:\n",
    "        df.to_csv('all_data.csv' ,index = False)\n",
    "        flag=False\n",
    "    else:\n",
    "        df.to_csv('all_data.csv' ,index = False,header=False,mode=\"a\")\n",
    "    #os.remove(str(csv_files[i]))\n",
    "    print(\"The pre-processing phase of the \",csv_files[i],\" file is completed.\\n\")\n",
    "    \n",
    "\n",
    "print(\"mission accomplished!\")\n",
    "print(\"Total operation time: = \",time.time()- seconds ,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-notebook",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
