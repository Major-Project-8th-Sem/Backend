{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# All  import statements needed for the notebook\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.metrics import *"
      ],
      "metadata": {
        "id": "6YrRqK7dV6FE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHjTgYWwV7X0",
        "outputId": "afaa5eb5-6dab-4bcc-97e2-a6da287135fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSEnWiOQV8db",
        "outputId": "41fbf89b-1868-4e2d-d1c9-1195babdb36d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/models/model_split_softmax_cnn_model.hdf5')"
      ],
      "metadata": {
        "id": "8C_L4_fMV9q-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/balancedhalf_data.csv')\n",
        "data.drop(data.columns[0] , inplace=True , axis=1)\n",
        "unknown = ['SSH-Patator','DoS slowloris','DoS Slowhttptest','Bot','Infiltration','Heartbleed']\n",
        "att = data.loc[(data['Label'].isin(unknown))]\n",
        "data.drop(att.index,axis=0 , inplace=True, errors='ignore')\n",
        "# importing required libraries for normalizing data\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# selecting numeric attributes columns from data\n",
        "numeric_col = data.select_dtypes(include='number').columns\n",
        "# using standard scaler for normalizing\n",
        "std_scaler = MinMaxScaler()\n",
        "def normalization(df,att,col):\n",
        "  for i in col:\n",
        "    arr = df[i]\n",
        "    arr = np.array(arr)\n",
        "    x = np.array(att[i])\n",
        "    df[i] = std_scaler.fit_transform(arr.reshape(len(arr),1))\n",
        "    #To use the same scaler which was used in preprocessing the train data \n",
        "    att[i] = std_scaler.transform(x.reshape(len(x),1))\n",
        "  return df,att\n",
        "# calling the normalization() function\n",
        "data , att = normalization(data.copy(),att.copy(),numeric_col)\n",
        "att.Label = 'unknown'\n",
        "X = att.drop('Label' , axis=1)\n",
        "X = X.to_numpy().reshape(-1, 83,1)\n",
        "\n",
        "y = att.Label\n",
        "X_train = data.drop('Label' , axis=1)\n",
        "X_train = X_train.to_numpy().reshape(-1, 83,1)\n",
        "\n",
        "y_train = data.Label"
      ],
      "metadata": {
        "id": "MxMqSWx1V_gH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(X)\n",
        "Y_train_predicted = model.predict(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_UnTisHWCZT",
        "outputId": "257d74a0-3ca5-41d9-efcc-001c9bd70cb3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "601/601 [==============================] - 8s 2ms/step\n",
            "34117/34117 [==============================] - 77s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_probailities_set(prob):\n",
        "    import numpy as np\n",
        "    prob = np.array(prob)\n",
        "    newp = np.prod(1-prob)\n",
        "    prob = prob/(1+newp) ## for existing probabilty\n",
        "    newp = newp/(1+newp)\n",
        "    prob = np.append(prob,newp)\n",
        "    return prob"
      ],
      "metadata": {
        "id": "0KTiYvHxWOrw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(predicted) , type(Y_train_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "677JM6HDWtU8",
        "outputId": "9715e956-1d1a-43f3-cc26-5fa77f338414"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = np.apply_along_axis(new_probailities_set,1,predicted)"
      ],
      "metadata": {
        "id": "sziuv4mLXTwg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_predicted = np.apply_along_axis(new_probailities_set,1,Y_train_predicted)"
      ],
      "metadata": {
        "id": "JfGSXGOKXToJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict = {\n",
        "    0 : 'BENIGN',\n",
        "    1 : 'DDoS',\n",
        "    2 : 'DoS Hulk',\n",
        "    3 : 'DoS GoldenEye',\n",
        "    4 : 'PortScan',\n",
        "    5 : 'FTP-Patator',\n",
        "    6:  'Unknown'\n",
        "}\n",
        "max_probability = np.amax(predicted, axis = 1)\n",
        "unknown_index = np.argmax(predicted, axis = 1)\n",
        "unknown_index_label = np.vectorize(my_dict.get)(unknown_index)\n",
        "max_probability_train = np.amax(Y_train_predicted, axis = 1)\n",
        "y_prediction_index = np.argmax(Y_train_predicted, axis = 1)\n",
        "y_prediction_test_label = np.vectorize(my_dict.get)(y_prediction_index)\n",
        "RIGHT_BOOLEAN = y_train == y_prediction_test_label"
      ],
      "metadata": {
        "id": "v2z6W1IGWGmt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL = data.shape[0]+att.shape[0]\n",
        "## calculate no of right predictions\n",
        "truepredicted = 0\n",
        "# 1.0 TRAIN SET:\n",
        "truepredicted += RIGHT_BOOLEAN.sum() ##simply check no of trues in train set...\n",
        "# 2.0 unknown set\n",
        "##here we have to check how many indices are unknown\n",
        "UNKNOWN_RIGHT_BOOLEAN = unknown_index_label == 'Unknown'\n",
        "truepredicted += UNKNOWN_RIGHT_BOOLEAN.sum()\n",
        "\n",
        "## ACCURACY PREDICTION:\n",
        "Accuracy = truepredicted/TOTAL\n",
        "print('Accuracy is ',Accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRGzYrR8Y1MT",
        "outputId": "6d945307-d876-467a-f276-9f66b3127174"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is  0.6149170246243695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNKNOWN_RIGHT_BOOLEAN.sum() ,  att.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcY_TEP9bBBw",
        "outputId": "415c944a-25dd-4889-d7c5-9d58555e93fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87, 19205)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RIGHT_BOOLEAN.sum() , data.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj94mTM3bXMo",
        "outputId": "2cc1100d-1316-4107-884c-434edb9daf43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(683044, 1091727)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhZj9izUbajz"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}